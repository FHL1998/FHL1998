---
title: "Embodied intelligence in manufacturing: leveraging large language models for autonomous industrial robotics"
collection: publications
category: manuscripts
permalink: /publication/2024-01-09-embodied-intelligence-number-1
excerpt: 'This paper explores using large language model (LLM) agents in industrial robotics, focusing on autonomous design, decision-making, and task execution. It introduces a framework with three key components: task-parameter matching, autonomous tool path design, and integration with robotic simulations. Results show GPT-4 excels in task planning, achieving an 81.88% success rate in simulations. The study highlights LLMs’ potential in manufacturing and suggests future improvements like visual semantic control and real-time feedback.'
date: 2024-01-09
venue: 'Journal 1'
paperurl: 'https://doi.org/10.1007/s10845-023-02294-y'
bibtexurl: 'http://academicpages.github.io/files/bibtex1.bib'
citation: 'Fan, Haolin, et al. "Embodied intelligence in manufacturing: leveraging large language models for autonomous industrial robotics." Journal of Intelligent Manufacturing 36.2 (2025): 1141-1157.'
---
This paper delves into the potential of Large Language Model (LLM) agents for industrial robotics, with an emphasis on autonomous design, decision-making, and task execution within manufacturing contexts. We propose a comprehensive framework that includes three core components: (1) matches manufacturing tasks with process parameters, emphasizing the challenges in LLM agents’ understanding of human-imposed constraints; (2) autonomously designs tool paths, highlighting the LLM agents’ proficiency in planar tasks and challenges in 3D spatial tasks; and (3) integrates embodied intelligence within industrial robotics simulations, showcasing the adaptability of LLM agents like GPT-4. Our experimental results underscore the distinctive performance of the GPT-4 agent, especially in Component 3, where it is outstanding in task planning and achieved a success rate of 81.88% across 10 samples in task completion. In conclusion, our study accentuates the transformative potential of LLM agents in industrial robotics and suggests specific avenues, such as visual semantic control and real-time feedback loops, for their enhancement.

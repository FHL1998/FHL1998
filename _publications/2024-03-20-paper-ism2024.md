---
title: "Unleashing the Potential of Large Language Models for Knowledge Augmentation: A Practical Experiment on Incremental Sheet Forming"
collection: publications
category: conferences
permalink: /publication/2024-03-20-paper-ism2024
excerpt: 'This research is presented at the International Conference on Industry 4.0 and Smart Manufacturing (ISM) 2024. It explores how Large Language Models (LLMs) can be adapted to better understand and operate within the Incremental Sheet Forming (ISF) domain. By developing an automated pipeline for extracting and enriching ISF-specific knowledge, and fine-tuning models like Alpaca-33B, the study achieves a 10.4% improvement in domain knowledge acquisition over GPT-3.5. A new conversational prototype further boosts accuracy and relevance, paving the way for advanced ISF applications such as knowledge graphs and quality prediction.'
date: 2024-03-20
venue: 'Procedia Computer Science'
paperurl: 'https://doi.org/10.1016/j.procs.2024.01.125'
citation: 'Fan, Haolin, et al. "Unleashing the potential of large language models for knowledge augmentation: A practical experiment on incremental sheet forming." Procedia Computer Science 232 (2024): 1269-1278.'
---

As the influence of Incremental Sheet Forming (ISF) grows in manufacturing sectors, so does the demand for precise and updated knowledge construction in this domain. In this research, we evaluate the capability of Large Language Models (LLMs) to capture domain-specific knowledge, using ISF as a case study. Recognizing common LLMs’ limitations such as potential inaccuracies and outdated information reliance, we propose a comprehensive approach involving automated and adaptive knowledge extraction, enrichment, and integration into an ISF-specific dataset. We then fine-tune the LLMs for ISF-related text classification and prompt response tasks. Our results reveal a significant enhancement in LLMs’ performance within the ISF domain, with a domain knowledge acquisition rate exceeding that of GPT-3.5 by 10.4%, achieved by the fine-tuned Alpaca-33B model. Additionally, we introduce a novel conversational prototype designed to refine the accuracy and relevance of LLMs in the ISF domain. Our findings will guide future efforts in downstream tasks such as ISF-domain knowledge graph construction and quality prediction.
